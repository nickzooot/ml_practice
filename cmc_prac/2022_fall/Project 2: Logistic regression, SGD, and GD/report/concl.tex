\section{\huge Общие выводы}

В рамках проведенного исследования были достигнуты поставленные цели и решены сформулированные в начале исследования задачи. Особенно хотелось бы выделить следующие результаты:
\begin{itemize}
	\item в рамках нашей задачи (задача определения токсичности комментария) лучшую обобщающую способность показал {\itshape стохастический градиентный спуск} 
	\item Размерность признакового пространства влияет на время работы градиентых методов, поэтому предобработка текстов: лемматизация, удаление стоп-слов и пр. является хорошей практикой. В том числе благодаря такой предобработки можно существенно повысить обобщающую способность модели.
	\item $batch\_size$ влияет обратно пропорционально на время работы SGD.
	\item выбор значения для {\itshape training rate} играет ключевую роль в задаче оптимизации: слишком маленькие значения являются причиной медленной сходимости, слишком большие значения осциллируют в окрестности минимума, так и не достигая его. Имеет смысл эвристически подбирать данный параметр.
	\item Tf-Idf не идеален, были рассмотрены случаи, когда BagOfWords превосходит его (например, в данной задаче так и было)
\end{itemize}