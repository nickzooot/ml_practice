\section{\huge Введение}
В задачах машинного обучения часто возникает необходимость минимизировать 
гладкие выпуклые функционалы. Задача нахождения минимума у таких функционалов
хорошо решается градиентными методами.

В данной работе рассматривалась
логистическая регрессия ({\itshape Logistic regression})~- линейный классификатор, 
главным преимуществом которого является корректное определение вероятности 
принадлежности объекта определенному классу. В логистической регресии необходимо 
минимизировать эмпирический риск с логистической функцией потерь.
На примере этого функционала была решена задача минимизации эмпирического 
риска для данных, содержащих в качестве признака комментарии из википедии, 
а в качестве целевой  переменной метку "токсичный"$\backslash$"не токсичный". Рассматривались 
такие градиентные методы как: {\itshape градиентный спуск} \ и {\itshape стохастический градиентный спуск}.
Исследовались оптимальные параметры данных методов для минимизации функции потерь. 
Оценивалось влияние предобработки текста с помощью лемматизации и выкидывания 
стоп-слов на точность предсказания, время работы, размер признакового пространства. 
Также были рассмотрены два метода векторизации: BagOfWords и Tf-Idf. В конце были 
проанализированы и указаны общие черты объектов, на которых была допущена ошибка.